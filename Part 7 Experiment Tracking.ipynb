{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc40ddd-c78e-4953-8104-f9491a3cd4b6",
   "metadata": {},
   "source": [
    "# Experiment Tracing\n",
    "Experiment Tracking helps figure out what works and what doesn't"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834b5ce-cf76-44cd-99d8-e6f032a82874",
   "metadata": {},
   "source": [
    "## 0. Getting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb1918d-9ba0-4a15-9d05-b4eab653fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "from going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d5bd1a-000f-4a48-bbac-b2b3ca918cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77df5cdf-a833-400b-b918-143315afebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random seed for torch operations\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d26da-402a-46ef-b8b6-c51a5bad6d14",
   "metadata": {},
   "source": [
    "## 1. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850296d0-c644-44ea-b354-40298567c495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data\\pizza_steak_sushi directory exists. skipping download...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/pizza_steak_sushi')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "def download_data(source: str, destination: str, remove_source: bool = True) -> Path:\n",
    "    \"\"\"Downloads a zipped dataset from the source and unzips to destination\"\"\"\n",
    "    data_path = Path(\"data\")\n",
    "    image_path = data_path/destination\n",
    "    if image_path.is_dir():\n",
    "        print(f\"[INFO] {image_path} directory exists. skipping download...\")\n",
    "        target_file = Path(source).name\n",
    "    else:\n",
    "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "        target_file = Path(source).name\n",
    "        with open(data_path/target_file,\"wb\") as f:\n",
    "            request = requests.get(source)\n",
    "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
    "            f.write(request.content)\n",
    "        with zipfile.ZipFile(data_path/target_file,\"r\") as zip_ref:\n",
    "            print(f\"[INFO] Unzipping {target_file} data...\")\n",
    "            zip_ref.extractall(image_path)\n",
    "        if remove_source:\n",
    "            os.remove(data_path/target_file)\n",
    "    return image_path\n",
    "\n",
    "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                           destination=\"pizza_steak_sushi\")\n",
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e9ecb-bf7e-459a-bd28-17836161523c",
   "metadata": {},
   "source": [
    "## 2. Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc700b9-d73a-4999-bff2-55369843e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created transforms: ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x189f71b8d00>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x189ef8592a0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = image_path/\"train\"\n",
    "test_dir = image_path/\"test\"\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "automatic_transforms = weights.transforms()\n",
    "print(f\"Automatically created transforms: {automatic_transforms}\")\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloader(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               transform=automatic_transforms,\n",
    "                                                                               batch_size=32)\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e777fd5-6fbe-425e-8d37-22c133352c14",
   "metadata": {},
   "source": [
    "## 3. Getting a pretrained model, freezing the base layers and changing the classifier head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e7e08e-693f-41ca-8c3e-e0841c0b1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3af79e8-7e76-4c0b-a9d6-3b84ced60f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape Output Shape Param #    Trainable\n",
       "====================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224] [32, 1000] --         True\n",
       "├─Sequential (features)                                      [32, 3, 224, 224] [32, 1280, 7, 7] --         True\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224] [32, 32, 112, 112] --         True\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224] [32, 32, 112, 112] 864        True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112] [32, 32, 112, 112] 64         True\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112] [32, 32, 112, 112] --         --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112] [32, 16, 112, 112] --         True\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112] [32, 16, 112, 112] 1,448      True\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112] [32, 24, 56, 56] --         True\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112] [32, 24, 56, 56] 6,004      True\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56] [32, 24, 56, 56] 10,710     True\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56] [32, 40, 28, 28] --         True\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56] [32, 40, 28, 28] 15,350     True\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28] [32, 40, 28, 28] 31,290     True\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28] [32, 80, 14, 14] --         True\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28] [32, 80, 14, 14] 37,130     True\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14] [32, 80, 14, 14] 102,900    True\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14] [32, 80, 14, 14] 102,900    True\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14] [32, 112, 14, 14] --         True\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14] [32, 112, 14, 14] 126,004    True\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14] [32, 112, 14, 14] 208,572    True\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14] [32, 112, 14, 14] 208,572    True\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14] [32, 192, 7, 7] --         True\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14] [32, 192, 7, 7] 262,492    True\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7] [32, 192, 7, 7] 587,952    True\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7] [32, 192, 7, 7] 587,952    True\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7] [32, 192, 7, 7] 587,952    True\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7] [32, 320, 7, 7] --         True\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7] [32, 320, 7, 7] 717,232    True\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7] [32, 1280, 7, 7] --         True\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7] [32, 1280, 7, 7] 409,600    True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7] [32, 1280, 7, 7] 2,560      True\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7] [32, 1280, 7, 7] --         --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7] [32, 1280, 1, 1] --         --\n",
       "├─Sequential (classifier)                                    [32, 1280] [32, 1000] --         True\n",
       "│    └─Dropout (0)                                           [32, 1280] [32, 1280] --         --\n",
       "│    └─Linear (1)                                            [32, 1280] [32, 1000] 1,281,000  True\n",
       "====================================================================================================\n",
       "Total params: 5,288,548\n",
       "Trainable params: 5,288,548\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 12.35\n",
       "====================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.35\n",
       "Params size (MB): 21.15\n",
       "Estimated Total Size (MB): 3492.77\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, \n",
    "        input_size=(32,3,224,224),\n",
    "        col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
    "        col_width=10,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86d4cb4c-8ee6-41cf-b1b5-d2e10629f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "set_seeds()\n",
    "model.classifier = torch.nn.Sequential(nn.Dropout(p=0.2,inplace=True),\n",
    "                                       nn.Linear(in_features=1280, out_features=len(class_names),bias=True)).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7cb329-bb45-4986-9672-79b9303fa475",
   "metadata": {},
   "source": [
    "## 4. Train model and track results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "340d607e-836c-46be-895f-252fda120c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd45572-90a2-4743-a1b2-895b9bb9903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0166d972-a661-427d-a940-9017959864d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device=device) -> Dict[str,List]:\n",
    "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "        print(f\"Epoch: {epoch+1} | train_loss: {train_loss:.4f} | train_acc: {train_acc:.4f} | test_loss: {test_loss:.4f} | test_acc: {test_acc:.4f}\")\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                            \"test_acc\": test_acc},\n",
    "                           global_step=epoch)\n",
    "        writer.add_graph(model=model,\n",
    "                         input_to_model=torch.randn(32,3,224,224).to(device))\n",
    "\n",
    "    writer.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3d996fd-eef3-4d30-8ead-c883b180462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0924 | train_acc: 0.3984 | test_loss: 0.9132 | test_acc: 0.5398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:17<01:11, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.8975 | train_acc: 0.6562 | test_loss: 0.7837 | test_acc: 0.8561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:34<00:51, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.8038 | train_acc: 0.7461 | test_loss: 0.6723 | test_acc: 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:51<00:34, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.6770 | train_acc: 0.8516 | test_loss: 0.6698 | test_acc: 0.8049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [01:09<00:17, 17.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.7065 | train_acc: 0.7188 | test_loss: 0.6746 | test_acc: 0.7737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:26<00:00, 17.31s/it]\n"
     ]
    }
   ],
   "source": [
    "set_seeds()\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=5,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cedc582f-1770-43b0-bb88-956f724de08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.0923891514539719,\n",
       "  0.8974885493516922,\n",
       "  0.8037762567400932,\n",
       "  0.6769649833440781,\n",
       "  0.7064977586269379],\n",
       " 'train_acc': [0.3984375, 0.65625, 0.74609375, 0.8515625, 0.71875],\n",
       " 'test_loss': [0.9132375717163086,\n",
       "  0.7837276458740234,\n",
       "  0.672258714834849,\n",
       "  0.6698037981987,\n",
       "  0.6745620767275492],\n",
       " 'test_acc': [0.5397727272727273,\n",
       "  0.8560606060606061,\n",
       "  0.8863636363636364,\n",
       "  0.8049242424242425,\n",
       "  0.7736742424242425]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be0920-c476-4b64-8525-406a363155cf",
   "metadata": {},
   "source": [
    "## 5. View our model's results in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ce4a8ba-91fa-45eb-a253-0ccad00744a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c9afb0a88ea1cbf5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c9afb0a88ea1cbf5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b809b4c-173f-446b-9d80-897316d18978",
   "metadata": {},
   "source": [
    "## 6. Create a helper function to build `SummaryWriter()` instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d64946d-4ff4-4b86-afea-b08ac831b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer(experiment_name: str,\n",
    "                  model_name: str,\n",
    "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    if extra:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f849b4-977a-4eb5-92a7-b968fe3dbc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python pytorch",
   "language": "python",
   "name": "venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
